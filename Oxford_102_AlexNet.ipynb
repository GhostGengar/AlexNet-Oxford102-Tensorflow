{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning AlexNet for Oxford-102\n",
    "**Author: Tien Dinh**\n",
    "\n",
    "This is a demonstration of the finetuning process done on pretrained weights from AlexNet (2012).\n",
    "\n",
    "* *Note: The `.py` version of the project will be available in the same repository.*\n",
    "\n",
    "## The dataset\n",
    "\n",
    "* The Oxford-102 dataset is a flower dataset with 102 classes of flowers.\n",
    "* The dataset can be found [here](http://www.robots.ox.ac.uk/~vgg/data/flowers/102/).\n",
    "\n",
    "## The network\n",
    "\n",
    "* AlexNet was created by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton in 2012 featuring a deep convolutional network.\n",
    "* AlexNet was the winner of **2012 ILSVRC** (ImageNet Large-Scale Visual Recognition Challenge).\n",
    "* The network features 6 layers of convolutional and pooling, and 3 layers of fully connected neural networks (the network architecture image will be included in this project).\n",
    "* Click [here](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) to read the research paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ImageNet mean\n",
    "* The mean of the ImageNet dataset, which was defined as `[104., 117., 124.]` was used to normalize the images.\n",
    "* The mean will help center all the images to around `0` (originally was from `0` to `255`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>`imagenet_mean = np.array([104., 117., 124.], dtype=np.float32)`</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The network architecture in TensorBoard\n",
    "<p align=\"center\">\n",
    "  <img src=\"./images/the_graph.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "imagenet_mean = np.array([104., 117., 124.], dtype=np.float32)\n",
    "\n",
    "os.mkdir('./summary')\n",
    "os.mkdir('./models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load up the train and test indexes\n",
    "\n",
    "* We are going to use `loadmat` from `scipy.io` to load MatLab file.\n",
    "* It is odd that there are more testing images than training images, so I decided to flip them to increase accuracy.\n",
    "* Converting them to list for easier iteration later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_ids = loadmat('setid.mat')\n",
    "test_ids = set_ids['trnid'].tolist()[0]\n",
    "train_ids = set_ids['tstid'].tolist()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing image indexes\n",
    "* Obtained that all the provided images were named from `00001` to `0xxxx` so we need a special function to pad the zeros in front of our indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indexes_processing(int_list):\n",
    "    returned_list = []\n",
    "    for index, element in enumerate(int_list):\n",
    "        returned_list.append(str(element))\n",
    "    for index, element in enumerate(returned_list):\n",
    "        if int(element) < 10:\n",
    "            returned_list[index] = '0000' + element\n",
    "        elif int(element) < 100:\n",
    "            returned_list[index] = '000' + element\n",
    "        elif int(element) < 1000:\n",
    "            returned_list[index] = '00' + element\n",
    "        else:\n",
    "            returned_list[index] = '0' + element\n",
    "    return returned_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_train_ids = indexes_processing(train_ids)\n",
    "raw_test_ids = indexes_processing(test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the labels for train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_labels = (loadmat('imagelabels.mat')['labels'] - 1).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['pink primrose', 'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea', 'english marigold', 'tiger lily', 'moon orchid', 'bird of paradise', 'monkshood', 'globe thistle', 'snapdragon', \"colt's foot\", 'king protea', 'spear thistle', 'yellow iris', 'globe-flower', 'purple coneflower', 'peruvian lily', 'balloon flower', 'giant white arum lily', 'fire lily', 'pincushion flower', 'fritillary', 'red ginger', 'grape hyacinth', 'corn poppy', 'prince of wales feathers', 'stemless gentian', 'artichoke', 'sweet william', 'carnation', 'garden phlox', 'love in the mist', 'mexican aster', 'alpine sea holly', 'ruby-lipped cattleya', 'cape flower', 'great masterwort', 'siam tulip', 'lenten rose', 'barbeton daisy', 'daffodil', 'sword lily', 'poinsettia', 'bolero deep blue', 'wallflower', 'marigold', 'buttercup', 'oxeye daisy', 'common dandelion', 'petunia', 'wild pansy', 'primula', 'sunflower', 'pelargonium', 'bishop of llandaff', 'gaura', 'geranium', 'orange dahlia', 'pink-yellow dahlia?', 'cautleya spicata', 'japanese anemone', 'black-eyed susan', 'silverbush', 'californian poppy', 'osteospermum', 'spring crocus', 'bearded iris', 'windflower', 'tree poppy', 'gazania', 'azalea', 'water lily', 'rose', 'thorn apple', 'morning glory', 'passion flower', 'lotus', 'toad lily', 'anthurium', 'frangipani', 'clematis', 'hibiscus', 'columbine', 'desert-rose', 'tree mallow', 'magnolia', 'cyclamen ', 'watercress', 'canna lily', 'hippeastrum ', 'bee balm', 'ball moss', 'foxglove', 'bougainvillea', 'camellia', 'mallow', 'mexican petunia', 'bromelia', 'blanket flower', 'trumpet creeper', 'blackberry lily']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing\n",
    "### Two Different Approaches, two distinct results\n",
    "#### 1. Normalize by dividing by `255`\n",
    "* Dividing by `255` to normalize the images between `0s` and `1s` is the way I usually do when I preprocess images to feed to Convolutional Neural Network.\n",
    "* The top accuracy for this method falls somewhere between `80%` and `82%`. This is not bad at all for a simple network architecture\n",
    "* Below is the snapshot during runtime of this method, the network converged to `80%` at epoch `20000` and did not improve further even with learning rate decay.\n",
    "\n",
    "```On Step 32500\n",
    "At: 2018-02-21 02:46:02.002311\n",
    "Accuracy: 81.96%\n",
    "Saving model...\n",
    "Model saved at step: 32500```\n",
    "\n",
    "\n",
    "```On Step 33000\n",
    "At: 2018-02-21 02:50:38.211141\n",
    "Accuracy: 82.25%\n",
    "Saving model...\n",
    "Model saved at step: 33000```\n",
    "\n",
    "\n",
    "```On Step 33500\n",
    "At: 2018-02-21 02:55:13.426248\n",
    "Accuracy: 82.35%\n",
    "Saving model...\n",
    "Model saved at step: 33500```\n",
    "#### 2. Normalize by subtracting the mean\n",
    "* This is by far the best method for AlexNet since the images used to feed this network were normalized this way.\n",
    "* Simply call `image -= mean` and `image` is ready to feed to the network.\n",
    "* The top accuracy for this method is around `90%`. This is absolutely amazing, I got `8%` accuracy boost just by using a different normalization approach.\n",
    "* The network also converged incredibly fast (see the output below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ImageProcessor():\n",
    "    \n",
    "    def __init__(self, num_classes=102):           \n",
    "        self.i = 0\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.training_images = np.zeros((6149, 227, 227, 3))\n",
    "        self.training_labels = None\n",
    "        \n",
    "        self.testing_images = np.zeros((1020, 227, 227, 3))\n",
    "        self.testing_labels = None\n",
    "    \n",
    "    def one_hot_encode(self, labels):\n",
    "        '''\n",
    "        One hot encode the output labels to be numpy arrays of 0s and 1s\n",
    "        '''\n",
    "        out = np.zeros((len(labels), self.num_classes))\n",
    "        for index, element in enumerate(labels):\n",
    "            out[index, element] = 1\n",
    "        return out\n",
    "    \n",
    "    def set_up_images(self):\n",
    "        print('Processing Training Images...')\n",
    "        i = 0\n",
    "        for element in raw_train_ids:\n",
    "            img = cv2.imread('/input/image_{}.jpg'.format(element))\n",
    "            img = cv2.resize(img, (227, 227)).astype(np.float32)\n",
    "            img -= imagenet_mean\n",
    "            self.training_images[i] = img\n",
    "            i += 1\n",
    "        print('Done!')\n",
    "        \n",
    "        i = 0\n",
    "        print('Processing Testing Images...')\n",
    "        for element in raw_test_ids:\n",
    "            img = cv2.imread('/input/image_{}.jpg'.format(element))\n",
    "            img = cv2.resize(img, (227, 227)).astype(np.float32)\n",
    "            img -= imagenet_mean\n",
    "            self.testing_images[i] = img\n",
    "            i += 1\n",
    "        print('Done!')\n",
    "        \n",
    "        print('Processing Training and Testing Labels...')\n",
    "        encoded_labels = self.one_hot_encode(image_labels)\n",
    "        for train_id in train_ids:\n",
    "            train_labels.append(encoded_labels[train_id - 1])\n",
    "        for test_id in test_ids:\n",
    "            test_labels.append(encoded_labels[test_id - 1])\n",
    "        self.training_labels = train_labels\n",
    "        self.testing_labels = test_labels\n",
    "        print('Done!')\n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        x = self.training_images[self.i:self.i + batch_size]\n",
    "        y = self.training_labels[self.i:self.i + batch_size]\n",
    "        self.i = (self.i + batch_size) % len(self.training_images)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize ImageProcessor instance\n",
    "image_processor = ImageProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Training Images...\n",
      "Done!\n",
      "Processing Testing Images...\n",
      "Done!\n",
      "Processing Training and Testing Labels...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Call set_up_images\n",
    "image_processor.set_up_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Architecture\n",
    "<p align=\"center\">\n",
    "  <img src=\"./images/alex_ar.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AlexNet():\n",
    "    \n",
    "    def __init__(self, X, keep_prob, num_classes, skip_layer, weights_path='DEFAULT'):\n",
    "        self.X = X\n",
    "        self.KEEP_PROB = keep_prob\n",
    "        self.NUM_CLASSES = num_classes\n",
    "        self.SKIP_LAYER = skip_layer\n",
    "        if weights_path == 'DEFAULT':\n",
    "            self.WEIGHTS_PATH = '/weights/bvlc_alexnet.npy'\n",
    "        else:\n",
    "            self.WEIGHTS_PATH = weights_path\n",
    "        \n",
    "        self.initialize()\n",
    "        \n",
    "    def initialize(self):\n",
    "        \n",
    "        # 1st Layer: Conv (w ReLu) -> Lrn -> Pool\n",
    "        conv_1 = self.conv_layer(self.X, 11, 11, 96, 4, 4, name='conv1', padding='VALID')\n",
    "        norm_1 = self.lrn(conv_1, 2, 1e-05, 0.75, name='norm1')\n",
    "        pool_1 = self.max_pool(norm_1, 3, 3, 2, 2, name='pool1', padding='VALID')\n",
    "        \n",
    "        # 2nd Layer: Conv (w ReLu) -> Lrn -> Pool\n",
    "        conv_2 = self.conv_layer(pool_1, 5, 5, 256, 1, 1, name='conv2', groups=2)\n",
    "        norm_2 = self.lrn(conv_2, 2, 1e-05, 0.75, name='norm2')\n",
    "        pool_2 = self.max_pool(norm_2, 3, 3, 2, 2, name='pool2', padding='VALID')\n",
    "        \n",
    "        # 3rd Layer: Conv (w ReLu)\n",
    "        conv_3 = self.conv_layer(pool_2, 3, 3, 384, 1, 1, name='conv3')\n",
    "\n",
    "        # 4th Layer: Conv (w ReLu)\n",
    "        conv_4 = self.conv_layer(conv_3, 3, 3, 384, 1, 1, name='conv4', groups=2)\n",
    "\n",
    "        # 5th Layer: Conv (w ReLu) -> Pool\n",
    "        conv_5 = self.conv_layer(conv_4, 3, 3, 256, 1, 1, name='conv5', groups=2)\n",
    "        pool_5 = self.max_pool(conv_5, 3, 3, 2, 2, name='pool5', padding='VALID')\n",
    "\n",
    "        # 6th Layer: Flatten -> FC (w ReLu) -> Dropout\n",
    "        pool_6_flat = tf.reshape(pool_5, [-1, 6*6*256])\n",
    "        full_6 = self.fully_connected(pool_6_flat, 6*6*256, 4096, name='fc6')\n",
    "        full_6_dropout = self.drop_out(full_6, self.KEEP_PROB)\n",
    "        \n",
    "        # 7th Layer: FC (w ReLu) -> Dropout\n",
    "        full_7 = self.fully_connected(full_6_dropout, 4096, 4096, name='fc7')\n",
    "        full_7_dropout = self.drop_out(full_7, self.KEEP_PROB)\n",
    "        \n",
    "        # 8th Layer: FC and return unscaled activations\n",
    "        self.y_pred = self.fully_connected(full_7_dropout, 4096, self.NUM_CLASSES, relu=False, name='fc8')\n",
    "        \n",
    "    def load_weights(self, session):\n",
    "        \n",
    "        # Load the weights into memory\n",
    "        weights_dict = np.load(self.WEIGHTS_PATH, encoding='bytes').item()\n",
    "        \n",
    "        # Loop over all layer names stored in the weights dict\n",
    "        for op_name in weights_dict:\n",
    "            # Check if layer should be trained from scratch\n",
    "            if op_name not in self.SKIP_LAYER:\n",
    "                with tf.variable_scope(op_name, reuse=True):\n",
    "                    for data in weights_dict[op_name]:\n",
    "                        if len(data.shape) == 1:\n",
    "                            var = tf.get_variable('biases')\n",
    "                            session.run(var.assign(data))\n",
    "                        else:\n",
    "                            var = tf.get_variable('weights')\n",
    "                            session.run(var.assign(data))\n",
    "                            \n",
    "    def conv_layer(self, x, filter_height, filter_width, num_filters, stride_y, stride_x, name, padding='SAME', groups=1):\n",
    "        num_channels = int(x.get_shape()[-1])\n",
    "        convolve = lambda i, k: tf.nn.conv2d(i, k, strides=[1,stride_y,stride_x,1], padding=padding)\n",
    "        with tf.variable_scope(name) as scope:\n",
    "            weights = tf.get_variable('weights', shape=[filter_height,\n",
    "                                                        filter_width,\n",
    "                                                        num_channels/groups,\n",
    "                                                        num_filters])\n",
    "            biases = tf.get_variable('biases', shape=[num_filters])\n",
    "        if groups == 1:\n",
    "            conv = convolve(x, weights)\n",
    "        else:\n",
    "            input_groups = tf.split(axis=3, num_or_size_splits=groups, value=x)\n",
    "            weight_groups = tf.split(axis=3, num_or_size_splits=groups, value=weights)\n",
    "            output_groups = [convolve(i, k) for i, k in zip(input_groups, weight_groups)]\n",
    "            conv = tf.concat(axis=3, values=output_groups)\n",
    "        bias = tf.reshape(tf.nn.bias_add(conv, biases), tf.shape(conv))\n",
    "        return tf.nn.relu(bias, name=scope.name)\n",
    "\n",
    "    def max_pool(self, x, filter_height, filter_width, stride_y, stride_x, name, padding='SAME'):\n",
    "        return tf.nn.max_pool(x, ksize=[1,filter_height,filter_width,1], \n",
    "                              strides=[1,stride_y,stride_x,1], padding=padding,\n",
    "                              name=name)\n",
    "\n",
    "    def lrn(self, x, radius, alpha, beta, name, bias=1.0):\n",
    "        return tf.nn.local_response_normalization(x, depth_radius=radius, \n",
    "                                                  alpha=alpha, beta=beta, \n",
    "                                                  bias=bias, name=name)\n",
    "\n",
    "    def fully_connected(self, input_layer, num_in, num_out, name, relu=True):\n",
    "        with tf.variable_scope(name) as scope:\n",
    "            weights = tf.get_variable('weights', shape=[num_in, num_out], trainable=True)\n",
    "            biases = tf.get_variable('biases', shape=[num_out], trainable=True)\n",
    "            activation = tf.nn.xw_plus_b(input_layer, weights, biases, name=scope.name)\n",
    "        if relu:\n",
    "            return tf.nn.relu(activation)\n",
    "        else:\n",
    "            return activation\n",
    "    \n",
    "    def drop_out(self, x, keep_prob):\n",
    "        return tf.nn.dropout(x, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders for inputs, outputs, and hold probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 227, 227, 3])\n",
    "y_true = tf.placeholder(tf.float32, [None, 102])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Hyperparameters\n",
    "* Epoch is set to 50000.\n",
    "* Drop rate is set to 0.5.\n",
    "\n",
    "*The parameter choices are adapted from [here](https://github.com/jimgoo/caffe-oxford102).*\n",
    "\n",
    "#### Learning rate decay\n",
    "### $$calculated = base \\times decay rate^{\\frac{global step}{decay step}}$$\n",
    "\n",
    "Where:\n",
    "* $calculated$ is the calculated learning rate.\n",
    "* $base$ is the base learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False)\n",
    "base_lr = 0.001\n",
    "base_lr = tf.train.exponential_decay(base_lr, global_step, 20000, 0.5, staircase=True)\n",
    "num_epochs = 50000\n",
    "drop_rate = 0.5\n",
    "train_layers = ['fc8']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking layers to train from scratch\n",
    "### 1. Choosing last two layers `fc7` and `fc8`\n",
    "* The network performs quite well at top accuracy of `77%`.\n",
    "* The learning rate are all the same for all variables.\n",
    "* All other variables are set to `trainable=False` to prevent learning.\n",
    "\n",
    "### 2. Choosing only the last `fc8` layer\n",
    "* The network performs well at top accuracy of `90%`.\n",
    "* The learning rates are different for each variables with pretrained weights learn slower.\n",
    "* All variables are trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = AlexNet(x, keep_prob, 102, train_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('network_output'):\n",
    "    y_pred = model.y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom learning rate\n",
    "### Pretrained layers\n",
    "* The pretrained layers include `conv1`, `conv2`, `conv3`, `conv4`, `conv5`, `fc6`, `fc7`.\n",
    "* The pretrained `weights` will have a learning rate of `1*base_lr`.\n",
    "* The pretrained `biases` will have a learning rate of `2*base_lr`.\n",
    "\n",
    "### Untrained layers\n",
    "* The untrained layer includes `fc8`.\n",
    "* The untrained `weights` will have a learning rate of `10*base_lr`.\n",
    "* The untrained `biases` will have a learning rate of `20*base_lr`.\n",
    "\n",
    "*`conv` means convolution layer, `fc` means fully connected layer.*\n",
    "\n",
    "*These learning rate choices are adapted from [here](https://github.com/jimgoo/caffe-oxford102).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Spliting variables into batches which have the same learning rate.\n",
    "all_vars = tf.global_variables()\n",
    "all_vars = all_vars[1:]\n",
    "conv_vars = [all_vars[0], all_vars[2], all_vars[4], all_vars[6], all_vars[8], all_vars[10], all_vars[12]]\n",
    "bias_vars = [all_vars[1], all_vars[3], all_vars[5], all_vars[7], all_vars[9], all_vars[11], all_vars[13]]\n",
    "last_weights = [all_vars[14]]\n",
    "last_bias = [all_vars[15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'cross_entropy_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.name_scope('cross_entropy'):\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred))\n",
    "    \n",
    "tf.summary.scalar('cross_entropy', cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    gradients = tf.gradients(cross_entropy, conv_vars + bias_vars + last_weights + last_bias)\n",
    "    conv_vars_gradients = gradients[:len(conv_vars)]\n",
    "    bias_vars_gradients = gradients[len(conv_vars):len(conv_vars) + len(bias_vars)]\n",
    "    last_weights_gradients = gradients[len(conv_vars) + len(bias_vars):len(conv_vars) + len(bias_vars) + len(last_weights)]\n",
    "    last_bias_gradients = gradients[len(conv_vars) + len(bias_vars) + len(last_weights):len(conv_vars) + len(bias_vars) + len(last_weights) + len(last_bias)]\n",
    "    \n",
    "trained_weights_optimizer = tf.train.GradientDescentOptimizer(base_lr)\n",
    "trained_biases_optimizer = tf.train.GradientDescentOptimizer(2*base_lr)\n",
    "weights_optimizer = tf.train.GradientDescentOptimizer(10*base_lr)\n",
    "biases_optimizer = tf.train.GradientDescentOptimizer(20*base_lr)\n",
    "\n",
    "train_op1 = trained_weights_optimizer.apply_gradients(zip(conv_vars_gradients, conv_vars))\n",
    "train_op2 = trained_biases_optimizer.apply_gradients(zip(bias_vars_gradients, bias_vars))\n",
    "train_op3 = weights_optimizer.apply_gradients(zip(last_weights_gradients, last_weights))\n",
    "train_op4 = biases_optimizer.apply_gradients(zip(last_bias_gradients, last_bias))\n",
    "\n",
    "train = tf.group(train_op1, train_op2, train_op3, train_op4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.name_scope('accuracy'):\n",
    "    matches = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "    acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "    \n",
    "tf.summary.scalar('accuracy', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_summary = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter('./summary')\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(max_to_keep=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training process started at 2018-02-22 06:50:01.159043\n",
      "On Step 0\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 06:50:03.418358\n",
      "Accuracy: 2.35%\n",
      "Saving model...\n",
      "Model saved at step: 0\n",
      "\n",
      "\n",
      "On Step 500\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 06:57:10.471321\n",
      "Accuracy: 45.29%\n",
      "Saving model...\n",
      "Model saved at step: 500\n",
      "\n",
      "\n",
      "On Step 1000\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 07:04:35.250569\n",
      "Accuracy: 52.55%\n",
      "Saving model...\n",
      "Model saved at step: 1000\n",
      "\n",
      "\n",
      "On Step 1500\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 07:12:13.779904\n",
      "Accuracy: 68.43%\n",
      "Saving model...\n",
      "Model saved at step: 1500\n",
      "\n",
      "\n",
      "On Step 2000\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 07:20:06.863819\n",
      "Accuracy: 77.25%\n",
      "Saving model...\n",
      "Model saved at step: 2000\n",
      "\n",
      "\n",
      "On Step 2500\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 07:28:20.584413\n",
      "Accuracy: 81.96%\n",
      "Saving model...\n",
      "Model saved at step: 2500\n",
      "\n",
      "\n",
      "On Step 3000\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 07:36:40.312540\n",
      "Accuracy: 84.22%\n",
      "Saving model...\n",
      "Model saved at step: 3000\n",
      "\n",
      "\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 07:45:22.559956\n",
      "Accuracy: 86.96%\n",
      "Saving model...\n",
      "Model saved at step: 3500\n",
      "\n",
      "\n",
      "On Step 4000\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 07:54:19.233832\n",
      "Accuracy: 87.06%\n",
      "Saving model...\n",
      "Model saved at step: 4000\n",
      "\n",
      "\n",
      "On Step 4500\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 08:03:34.177030\n",
      "Accuracy: 87.45%\n",
      "Saving model...\n",
      "Model saved at step: 4500\n",
      "\n",
      "\n",
      "On Step 5000\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 08:13:10.634582\n",
      "Accuracy: 88.14%\n",
      "Saving model...\n",
      "Model saved at step: 5000\n",
      "\n",
      "\n",
      "On Step 5500\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 08:22:56.650668\n",
      "Accuracy: 87.94%\n",
      "Saving model...\n",
      "Model saved at step: 5500\n",
      "\n",
      "\n",
      "On Step 6000\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 08:33:06.895660\n",
      "Accuracy: 88.24%\n",
      "Saving model...\n",
      "Model saved at step: 6000\n",
      "\n",
      "\n",
      "On Step 6500\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 08:43:28.349068\n",
      "Accuracy: 89.02%\n",
      "Saving model...\n",
      "Model saved at step: 6500\n",
      "\n",
      "\n",
      "On Step 7000\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 08:54:06.277382\n",
      "Accuracy: 88.63%\n",
      "Saving model...\n",
      "Model saved at step: 7000\n",
      "\n",
      "\n",
      "On Step 7500\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 09:05:01.780860\n",
      "Accuracy: 88.92%\n",
      "Saving model...\n",
      "Model saved at step: 7500\n",
      "\n",
      "\n",
      "On Step 8000\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 09:16:02.455828\n",
      "Accuracy: 88.82%\n",
      "Saving model...\n",
      "Model saved at step: 8000\n",
      "\n",
      "\n",
      "On Step 8500\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 09:27:22.524394\n",
      "Accuracy: 88.63%\n",
      "Saving model...\n",
      "Model saved at step: 8500\n",
      "\n",
      "\n",
      "On Step 9000\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 09:38:57.721870\n",
      "Accuracy: 88.33%\n",
      "Saving model...\n",
      "Model saved at step: 9000\n",
      "\n",
      "\n",
      "On Step 9500\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 09:50:52.914184\n",
      "Accuracy: 88.92%\n",
      "Saving model...\n",
      "Model saved at step: 9500\n",
      "\n",
      "\n",
      "On Step 10000\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 10:03:07.967029\n",
      "Accuracy: 88.43%\n",
      "Saving model...\n",
      "Model saved at step: 10000\n",
      "\n",
      "\n",
      "On Step 10500\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 10:15:40.359383\n",
      "Accuracy: 88.92%\n",
      "Saving model...\n",
      "Model saved at step: 10500\n",
      "\n",
      "\n",
      "On Step 11000\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 10:28:32.805685\n",
      "Accuracy: 89.61%\n",
      "Saving model...\n",
      "Model saved at step: 11000\n",
      "\n",
      "\n",
      "On Step 11500\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 10:41:41.304828\n",
      "Accuracy: 89.12%\n",
      "Saving model...\n",
      "Model saved at step: 11500\n",
      "\n",
      "\n",
      "On Step 12000\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 10:55:11.252563\n",
      "Accuracy: 89.61%\n",
      "Saving model...\n",
      "Model saved at step: 12000\n",
      "\n",
      "\n",
      "On Step 12500\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 11:09:00.707028\n",
      "Accuracy: 89.22%\n",
      "Saving model...\n",
      "Model saved at step: 12500\n",
      "\n",
      "\n",
      "On Step 13000\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 11:23:08.460219\n",
      "Accuracy: 89.41%\n",
      "Saving model...\n",
      "Model saved at step: 13000\n",
      "\n",
      "\n",
      "On Step 13500\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 11:37:37.642749\n",
      "Accuracy: 89.71%\n",
      "Saving model...\n",
      "Model saved at step: 13500\n",
      "\n",
      "\n",
      "On Step 14000\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 11:52:21.641734\n",
      "Accuracy: 89.22%\n",
      "Saving model...\n",
      "Model saved at step: 14000\n",
      "\n",
      "\n",
      "On Step 14500\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 12:07:25.218065\n",
      "Accuracy: 89.51%\n",
      "Saving model...\n",
      "Model saved at step: 14500\n",
      "\n",
      "\n",
      "On Step 15000\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 12:22:48.793025\n",
      "Accuracy: 89.51%\n",
      "Saving model...\n",
      "Model saved at step: 15000\n",
      "\n",
      "\n",
      "On Step 15500\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 12:38:38.434866\n",
      "Accuracy: 89.41%\n",
      "Saving model...\n",
      "Model saved at step: 15500\n",
      "\n",
      "\n",
      "On Step 16000\n",
      "Current base learning rate: 0.00100\n",
      "At: 2018-02-22 12:54:58.162456\n",
      "Accuracy: 89.51%\n",
      "Saving model...\n",
      "Model saved at step: 16000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer.add_graph(sess.graph)\n",
    "    model.load_weights(sess)\n",
    "    \n",
    "    print('Training process started at {}'.format(datetime.now()))\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "        batches = image_processor.next_batch(128)\n",
    "        sess.run(train, feed_dict={x:batches[0], y_true:batches[1], keep_prob:0.5})\n",
    "        global_step += 1\n",
    "        if (i%500==0):\n",
    "            print('On Step {}'.format(i))\n",
    "            print('Current base learning rate: {0:.5f}'.format(sess.run(base_lr)))\n",
    "            print('At: {}'.format(datetime.now()))\n",
    "            \n",
    "            accuracy = sess.run(acc, feed_dict={x:image_processor.testing_images, y_true:image_processor.testing_labels, keep_prob:1.0})\n",
    "            print('Accuracy: {0:.2f}%'.format(accuracy * 100))\n",
    "            \n",
    "            print('Saving model...')\n",
    "            saver.save(sess, './models/model_iter.ckpt', global_step=i)\n",
    "            print('Model saved at step: {}'.format(i))\n",
    "            print('\\n')\n",
    "            \n",
    "    print('Saving final model...')\n",
    "    saver.save(sess, './models/model_final.ckpt')\n",
    "    print('Saved')\n",
    "    print('Training finished at {}'.format(datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "* The model converges incredibly fast and reaches a stable accuracy of 90% at epoch 11000.\n",
    "* Training took 6 hours on one Tesla K80 GPU.\n",
    "* The whole process would take around 20 hours.\n",
    "\n",
    "### Final Accuracy: 89.51%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
